{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcac28d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs\n",
    "from scipy.stats import qmc\n",
    "from Utilities.plotting import newfig, savefig\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt\n",
    "from streamtracer import StreamTracer, VectorGrid\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7243bf86cc30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1234 \n",
    "random.seed(seed)          # Python標準乱数\n",
    "np.random.seed(seed)       # NumPy\n",
    "torch.manual_seed(seed)    # PyTorch (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8085372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_liner(b):\n",
    "    #(64, 64, 64, 3)\n",
    "    stride = 1\n",
    "    mask = np.abs(b[:, :, 0, 2]) > 50\n",
    "    seeds = np.stack([np.where(mask == True)[0], \n",
    "                    np.where(mask == True)[1], \n",
    "                    np.zeros_like(np.where(mask == True)[0])], axis=1)\n",
    "    seeds = seeds[::stride]\n",
    "    seeds.shape\n",
    "\n",
    "    b_resampled = b\n",
    "    nx, ny, nz, _ = b_resampled.shape\n",
    "    x = np.arange(nx)\n",
    "    y = np.arange(ny)\n",
    "    z = np.arange(nz)\n",
    "\n",
    "    xv, yv, zv = np.meshgrid(x, y, z, indexing='ij')\n",
    "    mesh = pv.StructuredGrid(xv, yv, zv)\n",
    "\n",
    "    bx, by, bz = b_resampled[..., 0], b_resampled[..., 1], b_resampled[..., 2]\n",
    "    vectors = np.stack([bx, by, bz], axis=-1).transpose(2, 1, 0, 3).reshape(-1, 3)\n",
    "\n",
    "    mesh[\"vector\"] = vectors\n",
    "    mesh.active_vectors_name = \"vector\"\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y, indexing='ij')\n",
    "    seeds_xs = np.stack([xx[seeds[:, 0], seeds[:, 1]], \n",
    "                        yy[seeds[:, 0], seeds[:, 1]], \n",
    "                        np.zeros_like(seeds[:, 0])], axis=1)\n",
    "    seeds_xs.shape\n",
    "    pv.global_theme.notebook = True\n",
    "    pv.global_theme.jupyter_backend = 'static'\n",
    "    # pv.global_theme.jupyter_backend = 'trame'\n",
    "    p = pv.Plotter(window_size=(1000, 600))\n",
    "\n",
    "    p.show_bounds(\n",
    "        grid='front',\n",
    "        show_xlabels=False,\n",
    "        show_ylabels=False,\n",
    "        show_zlabels=False,\n",
    "    )\n",
    "    p.add_mesh(mesh.outline(), color='k')\n",
    "\n",
    "    seed = pv.PolyData(seeds_xs)\n",
    "    strl = mesh.streamlines_from_source(seed, vectors='vector', integration_direction='both',\n",
    "                                        max_time=10000, initial_step_length=0.1)\n",
    "    p.add_mesh(strl.tube(radius=0.4), color='blue')\n",
    "\n",
    "    bottom_subset = mesh.extract_subset((0, nx-1, 0, ny-1, 0, 0)).extract_surface()\n",
    "    p.add_mesh(bottom_subset, cmap='gray', scalars='vector', component=2, clim=(-2000, 2000), \n",
    "            lighting=False, show_scalar_bar=False)\n",
    "\n",
    "    p.camera_position = \"xy\"\n",
    "    p.camera.roll = -30\n",
    "    p.camera.elevation = -70\n",
    "    p.camera.zoom(1.3)\n",
    "    p.show()\n",
    "\n",
    "def xyzmap_relative_error(train_b, ref_b, index, xyz_axis):\n",
    "    #(64, 64, 64, 3)\n",
    "    diff = np.linalg.norm(train_b - ref_b, axis=-1)  \n",
    "    norm = np.linalg.norm(ref_b, axis = -1) +  1e-8 \n",
    "    relative_error = diff/norm\n",
    "\n",
    "    # --- z固定の2Dスライスを取り出し ---\n",
    "    if xyz_axis == 0:\n",
    "        relative_error_slice = relative_error[:, index, :]  # (64,64)\n",
    "    else:\n",
    "        relative_error_slice = relative_error[:, :, index]\n",
    "    \n",
    "\n",
    "    print(relative_error_slice.shape)\n",
    "    # --- 可視化 ---\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(relative_error_slice.T, origin=\"lower\", cmap=\"inferno\")\n",
    "    plt.colorbar(label=\"Relative Error\")\n",
    "    plt.title(f\"Relative Error (z={index})\")\n",
    "    plt.xlabel(\"x index\")\n",
    "    plt.ylabel(\"y index\")\n",
    "    plt.show()\n",
    "    return relative_error_slice\n",
    "\n",
    "import os\n",
    "\n",
    "def remove_empty_dirs(root_dir):\n",
    "    for root, dirs, files in os.walk(root_dir, topdown=False):\n",
    "        for d in dirs:\n",
    "            path = os.path.join(root, d)\n",
    "            try:\n",
    "                if not os.listdir(path):  # 中身が空\n",
    "                    os.rmdir(path)\n",
    "                    print(f\"Removed empty dir: {path}\")\n",
    "            except OSError:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9253a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(nn.Module):\n",
    "\n",
    "    def __init__(self, x0, y0, bx0, by0, bz0, xyz_f, layers, min_xyz, max_xyz, TH, weight1, weight2, lr):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        z0 = np.zeros_like(x0)\n",
    "        i = 0\n",
    "\n",
    "\n",
    "        self.lb = torch.tensor(min_xyz, dtype=torch.float32).to(self.device)\n",
    "        self.ub = torch.tensor(max_xyz, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # training data\n",
    "        self.x0 = torch.tensor(x0, dtype=torch.float32).to(self.device)\n",
    "        self.y0 = torch.tensor(y0, dtype=torch.float32).to(self.device)\n",
    "        self.z0 = torch.tensor(z0, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.bx0 = torch.tensor(bx0, dtype=torch.float32).to(self.device)\n",
    "        self.by0 = torch.tensor(by0, dtype=torch.float32).to(self.device)\n",
    "        self.bz0 = torch.tensor(bz0, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.x_f = torch.tensor(xyz_f[:,0:1], dtype=torch.float32).to(self.device)\n",
    "        self.y_f = torch.tensor(xyz_f[:,1:2], dtype=torch.float32).to(self.device)\n",
    "        self.z_f = torch.tensor(xyz_f[:,2:3], dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.weight1 = weight1\n",
    "        self.weight2 = weight2\n",
    "        self.TH = TH\n",
    "        self.lr = lr\n",
    "        self.i = i\n",
    "\n",
    "\n",
    "        # NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        self.to(self.device)\n",
    "\n",
    "    # ---------------- NN ----------------\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = nn.ParameterList()\n",
    "        biases = nn.ParameterList()\n",
    "\n",
    "        for l in range(len(layers)-1):\n",
    "            W = nn.Parameter(torch.empty(layers[l], layers[l+1]))\n",
    "            nn.init.xavier_normal_(W)\n",
    "            b = nn.Parameter(torch.zeros(1, layers[l+1]))\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def neural_net(self, XYZ):\n",
    "        H = 2.0*(XYZ - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(len(self.weights)-1):\n",
    "            H = torch.tanh(H @ self.weights[l] + self.biases[l])\n",
    "        return H @ self.weights[-1] + self.biases[-1]\n",
    "\n",
    "    def net_b_bc(self, x, y, z):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "            y = y.unsqueeze(1)\n",
    "            z = z.unsqueeze(1)\n",
    "\n",
    "        x.requires_grad_(True)\n",
    "        y.requires_grad_(True)\n",
    "        z.requires_grad_(True)\n",
    "\n",
    "        bxyz = self.neural_net(torch.cat([x, y, z], dim=1))\n",
    "        #bxyz = 1e3*bxyz\n",
    "        bx, by, bz = bxyz[:,0:1], bxyz[:,1:2], bxyz[:,2:3]\n",
    "        #print(max(by))\n",
    "        return bx, by, bz\n",
    "\n",
    "    def net_b_div(self, x, y, z):\n",
    "        bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        bx_x = self.safe_grad(bx, x)\n",
    "        by_y = self.safe_grad(by, y)\n",
    "        bz_z = self.safe_grad(bz, z)\n",
    "        #print(max(bx_x + by_y + bz_z))\n",
    "\n",
    "        return bx_x + by_y + bz_z\n",
    "\n",
    "\n",
    "    def net_b_jxb(self, x, y, z):\n",
    "        bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        bz_y = self.safe_grad(bz, y)\n",
    "        by_z = self.safe_grad(by, z)\n",
    "        bx_z = self.safe_grad(bx, z)\n",
    "        bz_x = self.safe_grad(bz, x)\n",
    "        by_x = self.safe_grad(by, x)\n",
    "        bx_y = self.safe_grad(bx, y)\n",
    "\n",
    "        jx = bz_y - by_z\n",
    "        jy = bx_z - bz_x\n",
    "        jz = by_x - bx_y\n",
    "\n",
    "        jxb_x = jy*bz - jz*by\n",
    "        jxb_y = jz*bx - jx*bz\n",
    "        jxb_z = jx*by - jy*bx\n",
    "        #print(min(jxb_x**2 + jxb_y**2 + jxb_z**2))\n",
    "\n",
    "        return jxb_x**2 + jxb_y**2 + jxb_z**2\n",
    "\n",
    "    \n",
    "    def safe_grad(self, f, x):\n",
    "        g = torch.autograd.grad(\n",
    "            f, x,\n",
    "            grad_outputs=torch.ones_like(f),\n",
    "            create_graph=True,\n",
    "            allow_unused=True\n",
    "        )[0]\n",
    "        if g is None:\n",
    "            return torch.zeros_like(f)\n",
    "        return g\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # ---------------- Loss ----------------\n",
    "    def loss_fn(self):\n",
    "        bx0_pred, by0_pred, bz0_pred = self.net_b_bc(self.x0, self.y0, self.z0)\n",
    "        div_pred = self.net_b_div(self.x_f, self.y_f, self.z_f)\n",
    "        jxb_pred = self.net_b_jxb(self.x_f, self.y_f, self.z_f)\n",
    "\n",
    "        weight = self.weight1#[bc, div, jxb]\n",
    "        if self.i > self.TH:\n",
    "            weight = self.weight2\n",
    "        self.i = self.i + 1\n",
    "\n",
    "        loss = weight[0]*torch.mean((bx0_pred - self.bx0)**2) +\\\n",
    "            weight[0]*torch.mean((by0_pred - self.by0)**2) +\\\n",
    "            weight[0]*torch.mean((bz0_pred - self.bz0)**2) +\\\n",
    "            weight[1]*torch.mean(div_pred**2) +\\\n",
    "            weight[2]*torch.mean(jxb_pred)      \n",
    "        assert torch.isfinite(by0_pred).all(), f\"contains NaN or Inf\"#assertを負の数に関しても作成\n",
    "        assert torch.isfinite(bz0_pred).all(), f\"contains NaN or Inf\"\n",
    "        assert torch.isfinite(div_pred).all(), f\"contains NaN or Inf\"\n",
    "        assert torch.isfinite(jxb_pred).all(), f\"contains NaN or Inf\"\n",
    "        assert torch.isfinite(loss).all(), f\"contains NaN or Inf\"\n",
    "        print(f\"bx0 = {torch.mean((bx0_pred - self.bx0)**2)}, by0 = {torch.mean((by0_pred - self.by0)**2)}, bz0 = {weight[0]*torch.mean((bz0_pred - self.bz0)**2)}, div = {torch.mean((div_pred)**2)}, jxb = {torch.mean(jxb_pred)}\")\n",
    "        \n",
    "        return loss\n",
    "    def train_lbfgs(self):\n",
    "        self.train()\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(\n",
    "            self.parameters(),\n",
    "            max_iter=50000,\n",
    "            tolerance_grad=1e-10,\n",
    "            tolerance_change=1e-12,\n",
    "            history_size=50,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_fn(i = None)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                raise RuntimeError(\"NaN detected in LBFGS loss\")\n",
    "\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    def predict(self, xyz_star):\n",
    "        with torch.no_grad():  #計算グラフを作成しない\n",
    "            xyz_star = torch.tensor(\n",
    "                xyz_star, dtype=torch.float32, device=self.device\n",
    "            )\n",
    "\n",
    "            x = xyz_star[:, 0:1]\n",
    "            y = xyz_star[:, 1:2]\n",
    "            z = xyz_star[:, 2:3]\n",
    "\n",
    "            bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        return (\n",
    "            bx.cpu().numpy(),\n",
    "            by.cpu().numpy(),\n",
    "            bz.cpu().numpy()\n",
    "        )\n",
    "    \n",
    "    def train_model(self, n_iter):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
    "        for i in range(n_iter):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_fn()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{i}, loss={loss.item():.3e}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0eb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.7.0+cu126\n",
      "cuda available: False\n",
      "cuda device count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"cuda device count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019e444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPUで書き換え、GPUコードを訂正\n",
    "\n",
    "\n",
    "class PhysicsInformedNN(nn.Module):\n",
    "\n",
    "    def __init__(self, x0, y0, bx0, by0, bz0, xyz_f, layers, min_xyz, max_xyz, TH, weight1, weight2, lr):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "\n",
    "        z0 = np.zeros_like(x0)\n",
    "        i = 0\n",
    "\n",
    "\n",
    "        self.lb = torch.tensor(min_xyz, dtype=torch.float32).to(self.device)\n",
    "        self.ub = torch.tensor(max_xyz, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # training data\n",
    "        self.x0 = torch.tensor(x0, dtype=torch.float32).to(self.device)\n",
    "        self.y0 = torch.tensor(y0, dtype=torch.float32).to(self.device)\n",
    "        self.z0 = torch.tensor(z0, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.bx0 = torch.tensor(bx0, dtype=torch.float32).to(self.device)\n",
    "        self.by0 = torch.tensor(by0, dtype=torch.float32).to(self.device)\n",
    "        self.bz0 = torch.tensor(bz0, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.x_f = torch.tensor(xyz_f[:,0:1], dtype=torch.float32).to(self.device)\n",
    "        self.y_f = torch.tensor(xyz_f[:,1:2], dtype=torch.float32).to(self.device)\n",
    "        self.z_f = torch.tensor(xyz_f[:,2:3], dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.weight = weight1\n",
    "        self.weight1 = weight1\n",
    "        self.weight2 = weight2\n",
    "        self.TH = TH\n",
    "        self.lr = lr\n",
    "        self.i = i\n",
    "\n",
    "\n",
    "        # NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        self.to(self.device)\n",
    "\n",
    "    # ---------------- NN ----------------\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = nn.ParameterList()\n",
    "        biases = nn.ParameterList()\n",
    "\n",
    "        for l in range(len(layers)-1):\n",
    "            W = nn.Parameter(torch.empty(layers[l], layers[l+1]))\n",
    "            nn.init.xavier_normal_(W)\n",
    "            b = nn.Parameter(torch.zeros(1, layers[l+1]))\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def neural_net(self, XYZ):\n",
    "        H = 2.0*(XYZ - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(len(self.weights)-1):\n",
    "            H = torch.tanh(H @ self.weights[l] + self.biases[l])\n",
    "        return H @ self.weights[-1] + self.biases[-1]\n",
    "\n",
    "    def net_b_bc(self, x, y, z):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "            y = y.unsqueeze(1)\n",
    "            z = z.unsqueeze(1)\n",
    "\n",
    "        x.requires_grad_(True)\n",
    "        y.requires_grad_(True)\n",
    "        z.requires_grad_(True)\n",
    "\n",
    "        bxyz = self.neural_net(torch.cat([x, y, z], dim=1))\n",
    "        #bxyz = 1e3*bxyz\n",
    "        bx, by, bz = bxyz[:,0:1], bxyz[:,1:2], bxyz[:,2:3]\n",
    "        #print(max(by))\n",
    "        return bx, by, bz\n",
    "\n",
    "    def net_b_div(self, x, y, z):\n",
    "        bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        bx_x = self.safe_grad(bx, x)\n",
    "        by_y = self.safe_grad(by, y)\n",
    "        bz_z = self.safe_grad(bz, z)\n",
    "        #print(max(bx_x + by_y + bz_z))\n",
    "\n",
    "        return bx_x + by_y + bz_z\n",
    "\n",
    "\n",
    "    def net_b_jxb(self, x, y, z):\n",
    "        bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        bz_y = self.safe_grad(bz, y)\n",
    "        by_z = self.safe_grad(by, z)\n",
    "        bx_z = self.safe_grad(bx, z)\n",
    "        bz_x = self.safe_grad(bz, x)\n",
    "        by_x = self.safe_grad(by, x)\n",
    "        bx_y = self.safe_grad(bx, y)\n",
    "\n",
    "        jx = bz_y - by_z\n",
    "        jy = bx_z - bz_x\n",
    "        jz = by_x - bx_y\n",
    "\n",
    "        jxb_x = jy*bz - jz*by\n",
    "        jxb_y = jz*bx - jx*bz\n",
    "        jxb_z = jx*by - jy*bx\n",
    "        #print(min(jxb_x**2 + jxb_y**2 + jxb_z**2))\n",
    "\n",
    "        return jxb_x**2 + jxb_y**2 + jxb_z**2\n",
    "\n",
    "    \n",
    "    def safe_grad(self, f, x):\n",
    "        g = torch.autograd.grad(\n",
    "            f, x,\n",
    "            grad_outputs=torch.ones_like(f),\n",
    "            create_graph=True,\n",
    "            allow_unused=True\n",
    "        )[0]\n",
    "        if g is None:\n",
    "            return torch.zeros_like(f)\n",
    "        return g\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # ---------------- Loss ----------------\n",
    "    def loss_fn(self):\n",
    "        bx0_pred, by0_pred, bz0_pred = self.net_b_bc(self.x0, self.y0, self.z0)\n",
    "        div_pred = self.net_b_div(self.x_f, self.y_f, self.z_f)\n",
    "        jxb_pred = self.net_b_jxb(self.x_f, self.y_f, self.z_f)\n",
    "\n",
    "\n",
    "        loss = self.weight[0]*torch.mean((bx0_pred - self.bx0)**2) +\\\n",
    "            self.weight[0]*torch.mean((by0_pred - self.by0)**2) +\\\n",
    "            self.weight[0]*torch.mean((bz0_pred - self.bz0)**2) +\\\n",
    "            self.weight[1]*torch.mean(div_pred**2) +\\\n",
    "            self.weight[2]*torch.mean(jxb_pred)      \n",
    "        #assert torch.isfinite(by0_pred).all(), f\"contains NaN or Inf\"assertを負の数に関しても作成\n",
    "        print(f\"bx0 = {torch.mean((bx0_pred - self.bx0)**2)}, by0 = {torch.mean((by0_pred - self.by0)**2)}, bz0 = {torch.mean((bz0_pred - self.bz0)**2)}, div = {torch.mean((div_pred)**2)}, jxb = {torch.mean(jxb_pred)}\")\n",
    "        \n",
    "        return loss\n",
    "    def train_lbfgs(self):\n",
    "        self.train()\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(\n",
    "            self.parameters(),\n",
    "            max_iter=50000,\n",
    "            tolerance_grad=1e-10,\n",
    "            tolerance_change=1e-12,\n",
    "            history_size=50,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_fn()\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                raise RuntimeError(\"NaN detected in LBFGS loss\")\n",
    "\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    def predict(self, xyz_star):\n",
    "        with torch.no_grad():  #計算グラフを作成しない\n",
    "            xyz_star = torch.tensor(\n",
    "                xyz_star, dtype=torch.float32, device=self.device\n",
    "            )\n",
    "\n",
    "            x = xyz_star[:, 0:1]\n",
    "            y = xyz_star[:, 1:2]\n",
    "            z = xyz_star[:, 2:3]\n",
    "\n",
    "            bx, by, bz = self.net_b_bc(x, y, z)\n",
    "\n",
    "        return (\n",
    "            bx.cpu().numpy(),\n",
    "            by.cpu().numpy(),\n",
    "            bz.cpu().numpy()\n",
    "        )\n",
    "    \"\"\"\n",
    "    def train_model(self, n_iter):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
    "        for i in range(n_iter):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss_fn(i)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{i}, loss={loss.item():.3e}\")\n",
    "    \"\"\"\n",
    "\n",
    "    def save_checkpoint(self, path, optimizer, step):\n",
    "        torch.save({\n",
    "            \"step\": step,\n",
    "            \"model_state_dict\": self.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }, path)\n",
    "\n",
    "\n",
    "    def load_checkpoint(self, path, optimizer=None):\n",
    "        checkpoint = torch.load(path, map_location=self.device)#CPUとGPUの違いを読み込みload\n",
    "\n",
    "        # case 1: full checkpoint dict\n",
    "        if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "            self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            if optimizer is not None and \"optimizer_state_dict\" in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            step = checkpoint.get(\"step\", 0)\n",
    "\n",
    "        # case 2: state_dict only\n",
    "        else:\n",
    "            self.load_state_dict(checkpoint)\n",
    "            step = 0\n",
    "\n",
    "        return step\n",
    "\n",
    "    \n",
    "    def train_model(self, n_iter, ckpt_dir, checkpoint_path=None,  save_every=50000):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
    "\n",
    "        start_iter = 0\n",
    "        if checkpoint_path is not None and os.path.exists(checkpoint_path):\n",
    "            start_iter = self.load_checkpoint(checkpoint_path, optimizer)\n",
    "            ckpt_dir = os.path.dirname(checkpoint_path)\n",
    "            print(f\"Resumed from step {start_iter}\")\n",
    "\n",
    "        for i in range(start_iter, n_iter):\n",
    "            optimizer.zero_grad()\n",
    "            self.weight = self.weight1#[bc, div, jxb]\n",
    "            if i > self.TH:\n",
    "                self.weight = self.weight2\n",
    "          \n",
    "            loss = self.loss_fn()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{i}, loss={loss.item():.3e}\")\n",
    "\n",
    "            if (i + 1) % save_every == 0:\n",
    "                ckpt_path = os.path.join(ckpt_dir, f\"checkpoint_{i+1}.pt\")\n",
    "                self.save_checkpoint(ckpt_path, optimizer, i + 1)\n",
    "                print(f\"Checkpoint saved at step {i+1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8c5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:[3, 256, 256, 256, 256, 256, 256, 3]\n",
      "sampling_points:32768, bc_sampling_points:64\n",
      "weight1:[100, 1, 1], weight2[1, 10, 10], Threshold100000, learning:0.001\n",
      "cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m#学習率を途中で変更してみる\u001b[39;00m\n\u001b[32m     71\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m500000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m#model.train_model(100)\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m#model.train_lbfgs()\u001b[39;00m\n\u001b[32m     75\u001b[39m elapsed = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 224\u001b[39m, in \u001b[36mPhysicsInformedNN.train_model\u001b[39m\u001b[34m(self, n_iter, ckpt_dir, checkpoint_path, save_every)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_iter, ckpt_dir, checkpoint_path=\u001b[38;5;28;01mNone\u001b[39;00m,  save_every=\u001b[32m50000\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     start_iter = \u001b[32m0\u001b[39m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os.path.exists(checkpoint_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/optim/adam.py:100\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/optim/optimizer.py:369\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    366\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:53\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_break_reasons, guard_failures, orig_code_map, reset_frame_count\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Register polyfill functions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolyfills\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loader \u001b[38;5;28;01mas\u001b[39;00m _  \u001b[38;5;66;03m# usort: skip # noqa: F401\u001b[39;00m\n\u001b[32m     56\u001b[39m __all__ = [\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_in_graph\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massume_constant_result\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m ]\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# allowlist this for weights_only load of NJTs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py:25\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# See also the TYPE_CHECKING block in torch/_dynamo/polyfills/__init__.py\u001b[39;00m\n\u001b[32m     15\u001b[39m POLYFILLED_MODULE_NAMES: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ...] = (\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbuiltins\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfunctools\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m POLYFILLED_MODULES: \u001b[38;5;28mtuple\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mModuleType\u001b[39m\u001b[33m\"\u001b[39m, ...] = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolyfills\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPOLYFILLED_MODULE_NAMES\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Unregister the builtin functions from _builtin_function_ids to let them to be\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# dispatched with the appropriate VariableTracker type. Otherwise, they will be\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# dispatched with BuiltinVariable if present in _builtin_function_ids.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m polyfill_module \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py:26\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# See also the TYPE_CHECKING block in torch/_dynamo/polyfills/__init__.py\u001b[39;00m\n\u001b[32m     15\u001b[39m POLYFILLED_MODULE_NAMES: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ...] = (\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbuiltins\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfunctools\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m POLYFILLED_MODULES: \u001b[38;5;28mtuple\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mModuleType\u001b[39m\u001b[33m\"\u001b[39m, ...] = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolyfills\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULE_NAMES\n\u001b[32m     28\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Unregister the builtin functions from _builtin_function_ids to let them to be\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# dispatched with the appropriate VariableTracker type. Otherwise, they will be\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# dispatched with BuiltinVariable if present in _builtin_function_ids.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m polyfill_module \u001b[38;5;129;01min\u001b[39;00m POLYFILLED_MODULES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/polyfills/builtins.py:30\u001b[39m\n\u001b[32m     19\u001b[39m __all__ = [\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33many\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33menumerate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m ]\n\u001b[32m     27\u001b[39m _T = TypeVar(\u001b[33m\"\u001b[39m\u001b[33m_T\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;129;43m@substitute_in_graph\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_constant_fold_through\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:427\u001b[39m, in \u001b[36msubstitute_in_graph.<locals>.wrapper\u001b[39m\u001b[34m(traceable_fn)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(original_fn) \u001b[38;5;129;01min\u001b[39;00m _polyfilled_function_ids:\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuplicate polyfilled object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m rule_map: \u001b[38;5;28mdict\u001b[39m[Any, \u001b[38;5;28mtype\u001b[39m[VariableTracker]] = \u001b[43mget_torch_obj_rule_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_fn \u001b[38;5;129;01min\u001b[39;00m rule_map:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    430\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuplicate object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with different rules: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPolyfilledFunctionVariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule_map[original_fn]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2870\u001b[39m, in \u001b[36mget_torch_obj_rule_map\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2868\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m m.items():  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   2869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m.py#\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k:\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m         obj = \u001b[43mload_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2871\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2872\u001b[39m         obj = _module_dir(torch) + k[\u001b[38;5;28mlen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtorch/\u001b[39m\u001b[33m\"\u001b[39m) :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2901\u001b[39m, in \u001b[36mload_object\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2899\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2900\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) == \u001b[32m1\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid obj name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2901\u001b[39m         val = \u001b[43m_load_obj_from_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2902\u001b[39m     val = unwrap_if_wrapper(val)\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:2885\u001b[39m, in \u001b[36m_load_obj_from_str\u001b[39m\u001b[34m(fully_qualified_name)\u001b[39m\n\u001b[32m   2883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_obj_from_str\u001b[39m(fully_qualified_name):\n\u001b[32m   2884\u001b[39m     module, obj_name = fully_qualified_name.rsplit(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, maxsplit=\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2885\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m, obj_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dispatch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suspend_functionalization\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maot_autograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AOTConfig, create_joint\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     _has_potential_branch_input_alias,\n\u001b[32m      9\u001b[39m     _has_potential_branch_input_mutation,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     UnsupportedAliasMutationException,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HigherOrderOperator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:135\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_aot_autograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraced_function_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    113\u001b[39m     aot_dispatch_subclass,\n\u001b[32m    114\u001b[39m     create_functional_call,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m     fn_prepped_for_autograd,\n\u001b[32m    120\u001b[39m )\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_aot_autograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    122\u001b[39m     _get_autocast_states,\n\u001b[32m    123\u001b[39m     _get_symint_hints,\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m     strict_zip,\n\u001b[32m    134\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartitioners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m default_partition\n\u001b[32m    138\u001b[39m \u001b[38;5;28mzip\u001b[39m = strict_zip\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# This global counter increments every time we compile a graph with\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# AOTAutograd.  You can use this to correlate runtime error messages\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# with compile time (e.g., if you get an error at runtime saying\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# one counter is allocated per entire compiled block (but this block\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# may involve compiling multiple subgraphs; e.g., for forwards/backwards)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointPolicy\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_activation_checkpointing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_info_provider\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphInfoProvider\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_activation_checkpointing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mknapsack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     39\u001b[39m     dp_knapsack,\n\u001b[32m     40\u001b[39m     greedy_knapsack,\n\u001b[32m     41\u001b[39m     ilp_knapsack,\n\u001b[32m     42\u001b[39m )\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_activation_checkpointing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mknapsack_evaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KnapsackEvaluator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/graph_info_provider.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Graph, Node\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGraphInfoProvider\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/networkx/__init__.py:46\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreadwrite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Need to test with SciPy, when available\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithms\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linalg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/networkx/algorithms/__init__.py:65\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwiener\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Make certain subpackages available to the user as direct imports from\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# the `networkx` namespace.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m approximation\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assortativity\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bipartite\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/template_pytorch/.pinnvenv/lib/python3.12/site-packages/networkx/algorithms/approximation/__init__.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapproximation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering_coefficient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapproximation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclique\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapproximation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectivity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapproximation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance_measures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapproximation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdominating_set\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1528\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1502\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1601\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "noise = 0.0        \n",
    "\n",
    "# 空間の大きさと分解能\n",
    "x = np.linspace(0, 63, 64)\n",
    "y = np.linspace(0, 63, 64)\n",
    "z = np.linspace(0, 63, 64)\n",
    "max_xyz = np.array([63, 63, 63])\n",
    "min_xyz = np.array([0.0, 0.0, 0.0])\n",
    "#print(min_xyz)\n",
    "\n",
    "N_b = 64#境界条件の点\n",
    "N_f = 64*64*8#コロケーション \n",
    "layers = [3, 256, 256, 256, 256,  256, 256,  3]#層の接続\n",
    "lowlou_f = \"/workspaces/template_pytorch/rtmag/lowlou/test/b_0.210_0.124.npz\"\n",
    "\n",
    "data = np.load(lowlou_f)\n",
    "Exa_b = data[\"b\"]#(64, 64, 64, 3)\n",
    "bottom = Exa_b[:, :, 0, :]\n",
    "\n",
    "Exa_bx = bottom[:, :, 0:1]\n",
    "Exa_by = bottom[:, :, 1:2]\n",
    "Exa_bz = bottom[:, :, 2:3]\n",
    "\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "#print(X)\n",
    "\n",
    "xyz_star = np.hstack((X.flatten()[:,None], Y.flatten()[:,None], Z.flatten()[:,None]))\n",
    "\n",
    "x_star = Exa_bx.T.flatten()[:,None] \n",
    "y_star = Exa_by.T.flatten()[:,None]\n",
    "z_star = Exa_bz.T.flatten()[:,None]\n",
    "\n",
    "idx_x = np.random.choice(x.shape[0], N_b, replace=False)\n",
    "idx_y = np.random.choice(y.shape[0], N_b, replace=False)\n",
    "\n",
    "x0 = x[idx_x]\n",
    "y0 = y[idx_y]\n",
    "\n",
    "bx0 = Exa_bx[idx_x,idx_y, 0:1]#後ろの軸指定の有無\n",
    "by0 = Exa_by[idx_x,idx_y, 0:1]\n",
    "bz0 = Exa_bz[idx_x,idx_y, 0:1]\n",
    "\n",
    "\n",
    "sampler = qmc.Sobol(d=3, scramble=True, seed=1234) \n",
    "xyz_f = sampler.random(N_f)\n",
    "xyz_bc = sampler.random(100)\n",
    "\n",
    "xyz_f = np.array([0,0,0]) + np.array([63,63,63]) * xyz_f \n",
    "xyz_bc_points = np.array([63, 63, 0]) * xyz_bc \n",
    "xyz_f = np.vstack([xyz_f, xyz_bc_points])\n",
    "\n",
    "\n",
    "path = \"/workspaces/template_pytorch/PINNs-master/model\"\n",
    "num  = sum(1 for name in os.listdir(path) if os.path.isdir(os.path.join(path, name)))\n",
    "os.makedirs(f\"/workspaces/template_pytorch/PINNs-master/model/model{num}\", exist_ok=True)\n",
    "model_dir = f\"/workspaces/template_pytorch/PINNs-master/model/model{num}\"\n",
    "\n",
    "weight1,weight2 = [100, 1, 1], [1, 10, 10] \n",
    "TH = 100000\n",
    "lr = 1e-3\n",
    "\n",
    "print(f\"Layers:{layers}\")\n",
    "print(f\"sampling_points:{N_f}, bc_sampling_points:{N_b}\")\n",
    "print(f\"weight1:{weight1}, weight2{weight2}, Threshold{TH}, learning:{lr}\")\n",
    "\n",
    "\n",
    "model = PhysicsInformedNN(x0, y0, bx0, by0, bz0, xyz_f, layers, min_xyz, max_xyz, TH, weight1, weight2, lr)#lossをプロット\n",
    "#学習率を途中で変更してみる\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model.train_model(500000, model_dir, save_every=50000)\n",
    "#model.train_model(100)\n",
    "#model.train_lbfgs()\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Training time: {elapsed:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "bx_pred, by_pred, bz_pred= model.predict(xyz_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load→eval用\n",
    "model.load_checkpoint(\"/workspaces/template_pytorch/PINNs-master/model/model3/checkpoint_200000.pt\", optimizer=None)\n",
    "#model.train_lbfgs()\n",
    "model.eval()\n",
    "bx_pred, by_pred, bz_pred= model.predict(xyz_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b63a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty_dirs(\"/workspaces/template_pytorch/PINNs-master/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865f318",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bx_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x = \u001b[43mbx_pred\u001b[49m.reshape(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (262144,)\u001b[39;00m\n\u001b[32m      2\u001b[39m y = by_pred.reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m z = bz_pred.reshape(-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'bx_pred' is not defined"
     ]
    }
   ],
   "source": [
    "x = bx_pred.reshape(-1)  # (262144,)\n",
    "y = by_pred.reshape(-1)\n",
    "z = bz_pred.reshape(-1)\n",
    "\n",
    "x3 = x.reshape(64, 64, 64)\n",
    "y3 = y.reshape(64, 64, 64)\n",
    "z3 = z.reshape(64, 64, 64)\n",
    "\n",
    "b = np.stack([x3, y3, z3], axis=-1)\n",
    "\n",
    "print(b)\n",
    "max_abs_bz = np.max(np.abs(b[:, :, :, 2]))\n",
    "print(max_abs_bz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_liner(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzmap_relative_error(b, Exa_b, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bx_pred.reshape(-1)  # (262144,)\n",
    "y = by_pred.reshape(-1)\n",
    "z = bz_pred.reshape(-1)\n",
    "\n",
    "x3 = x.reshape(64, 64, 64)\n",
    "y3 = y.reshape(64, 64, 64)\n",
    "z3 = z.reshape(64, 64, 64)\n",
    "\n",
    "b = np.stack([x3, y3, z3], axis=-1)\n",
    "\n",
    "print(b)\n",
    "max_abs_bz = np.max(np.abs(b[:, :, :, 2]))\n",
    "print(max_abs_bz)\n",
    "box_liner(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcfe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Exa_b)\n",
    "max_abs_bz = np.max(np.abs(Exa_b[:, :, 0, 2]))\n",
    "print(max_abs_bz)\n",
    "box_liner(Exa_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
